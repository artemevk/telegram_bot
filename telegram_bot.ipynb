{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import random\n",
    "import nltk\n",
    "import pymorphy2\n",
    "import requests\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка логирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='app.log', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рабочий вариант c CalibratedClassifierCV\n",
    "def get_intent(text):\n",
    "    probas = clf.predict_proba(vectorizer.transform([text]))[0]\n",
    "#     print(len(probas))\n",
    "    proba = max(probas)\n",
    "#     print(proba)\n",
    "    index = list(probas).index(proba)\n",
    "#     print(index)\n",
    "    intent = clf.classes_[index]\n",
    "\n",
    "    logging.info('Намерение: {}. Точность определения: {}'.format(intent, proba))\n",
    "\n",
    "    if proba > 0.25:\n",
    "        index = list(probas).index(proba)\n",
    "#         print(index)\n",
    "        return clf.classes_[index]\n",
    "    \n",
    "    \n",
    "    \n",
    "# # Рабочий вариант c LinearSVC\n",
    "# def get_intent(text):\n",
    "#     probas = clf.decision_function(vectorizer.transform([text]))[0]\n",
    "#     print((probas))\n",
    "#     proba = max(probas)\n",
    "#     print('сумма:',sum(probas))\n",
    "#     print(proba)\n",
    "#     index = list(probas).index(proba)\n",
    "#     print(index)\n",
    "#     print(clf.classes_[index])\n",
    "#     print(clf.predict(vectorizer.transform([text]))[0])\n",
    "    \n",
    "#     if proba > -0.25:\n",
    "#         index = list(probas).index(proba)\n",
    "#         print(clf.classes_[index])\n",
    "#         return clf.classes_[index]\n",
    "\n",
    "\n",
    "# # Рабочий вариант с LogisticRegression\n",
    "# def get_intent(text):\n",
    "#     proba = clf.predict_proba(vectorizer.transform([text])[0], [text])\n",
    "#     probas.append(proba)\n",
    "#     print(proba, probas)\n",
    "#     proba = max(probas)\n",
    "#     if proba > 0.3:\n",
    "#         index = list(probas).index(proba)\n",
    "#         return clf.classes_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generative_response(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join(char for char in text if char in alphabet)\n",
    "    text = text.strip()\n",
    "    words = text.split(' ')\n",
    "\n",
    "    qas = []\n",
    "    for word in words:\n",
    "        if word in search_structure:\n",
    "            qas += search_structure[word]\n",
    "\n",
    "    for question, answer in qas:\n",
    "        if abs(len(text) - len(question)) < len(question) * 0.20:\n",
    "            edit_distance = nltk.edit_distance(text, question)\n",
    "            if edit_distance / len(question) < 0.20:\n",
    "                return answer\n",
    "\n",
    "\n",
    "list_intents_rzhunemogu = ['joke', 'joke_18']            \n",
    "            \n",
    "def get_data_from_rzhunemogu(intent):\n",
    "    if intent == 'joke':\n",
    "        url = r'http://rzhunemogu.ru/RandJSON.aspx?CType=1'\n",
    "        res = requests.get(url)\n",
    "        return res.text.split(':\"')[1][:-2]\n",
    "    elif intent == 'joke_18':\n",
    "        url = r'http://rzhunemogu.ru/RandJSON.aspx?CType=11'\n",
    "        res = requests.get(url)\n",
    "        return res.text.split(':\"')[1][:-2]\n",
    "\n",
    "def get_response_by_intent(intent):\n",
    "    if intent in list_intents_rzhunemogu:\n",
    "        response = get_data_from_rzhunemogu(intent)\n",
    "    else:\n",
    "        phrases = BOT_CONFIG['intents'][intent]['responses']\n",
    "        response = random.choice(phrases)\n",
    "    logging.info('Ответ BOT_CONFIG: {}'.format(response))\n",
    "    return response\n",
    "\n",
    "def get_phailure_phrase():    \n",
    "    phrases = BOT_CONFIG['failure_phrases']\n",
    "    response = random.choice(phrases)\n",
    "    logging.info('Ответ заглушкой: {}'.format(response))\n",
    "    return response\n",
    "\n",
    "\n",
    "def go_bot(text):\n",
    "    \n",
    "    logging.info('Запрос: {}'.format(text))\n",
    "    \n",
    "    \"\"\"Генерация ответной реплики\"\"\"\n",
    "    # NLU\n",
    "    intent = get_intent(text)\n",
    "\n",
    "    # Generate answer\n",
    "\n",
    "    # rules\n",
    "    if intent:\n",
    "        logging.info('Генерация подготовленного ответа')\n",
    "        return get_response_by_intent(intent)\n",
    "\n",
    "    # use generative model\n",
    "    response = get_generative_response(text)\n",
    "    if response:\n",
    "        logging.info('Генерация ответа из диалогов: {}'.format(response))\n",
    "        return response\n",
    "\n",
    "    # stub\n",
    "    return get_phailure_phrase()\n",
    "\n",
    "\n",
    "def start(update, context):\n",
    "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
    "    update.message.reply_text('Hi!')\n",
    "\n",
    "\n",
    "def help_command(update, context):\n",
    "    \"\"\"Send a message when the command /help is issued.\"\"\"\n",
    "    update.message.reply_text('Help!')\n",
    "\n",
    "\n",
    "def bot_answer(update, context):\n",
    "    \"\"\"Echo the user message.\"\"\"\n",
    "    question = update.message.text\n",
    "    answer = go_bot(question)\n",
    "    update.message.reply_text(answer)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Start the bot.\"\"\"\n",
    "    updater = Updater(\"1155028770:AAELo8cjnTp0fB4hAMjYgzO5oVnW1DshvSM\", use_context=True)\n",
    "\n",
    "    dp = updater.dispatcher\n",
    "    dp.add_handler(CommandHandler(\"start\", start))\n",
    "    dp.add_handler(CommandHandler(\"help\", help_command))\n",
    "    dp.add_handler(MessageHandler(Filters.text & ~Filters.command, bot_answer))\n",
    "\n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных для заготовленных ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# работаю с документом с заготовленными запросами-ответами\n",
    "with open('BOT_CONFIG.txt', encoding='utf-8') as conf:\n",
    "    BOT_CONFIG = eval(conf.read())\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# для приведения к нормальной форме всех запросов\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "# для удаления знаков припинания\n",
    "alphabet = '1234567890- абвгдеёжзийклмнопрстуфхцчшщъыьэюяqwertyuiopasdfghjklzxcvbnm'\n",
    "# для исключения повторных запросов\n",
    "examples = []\n",
    "i = 0\n",
    "\n",
    "for intent, intent_data in BOT_CONFIG['intents'].items():\n",
    "    for example in intent_data['examples']:\n",
    "        # пропускаю все запросы длинной меньше 4\n",
    "        if len(example) <= 3:\n",
    "            continue\n",
    "        example = example.lower() # приведение к нижнему регистру\n",
    "        example = morph.parse(example)[0].normal_form # приведение к нормальной форме\n",
    "        example = ''.join(char for char in example if char in alphabet) # удаление знаков препинания\n",
    "        if example not in examples:\n",
    "            examples.append(example)\n",
    "            dataset.append([example, intent])\n",
    "        else:\n",
    "            i += 1\n",
    "            \n",
    "print('Количество одинаковых запросов в конфигураторе бота:', i)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = [x for x, y in dataset]\n",
    "y = [y for x, y in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор модели обучения и качества обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 1\n",
    "# vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "\n",
    "# вариант 2\n",
    "# vectorizer = HashingVectorizer(analyzer='char_wb', ngram_range=(2, 3))\n",
    "\n",
    "# вариант 3\n",
    "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3))\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(X_text) # обучение\n",
    "\n",
    "probas = []\n",
    "\n",
    "for i in range(5):\n",
    "#     clf = LinearSVC() # вариант 1\n",
    "    # вариант 2\n",
    "    svm = LinearSVC()\n",
    "    clf = CalibratedClassifierCV(svm, method='sigmoid')\n",
    "#     clf = LogisticRegression() # вариант 3\n",
    "#     clf = SVC(kernel='precomputed') # вариант 4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    clf.fit(X_train, y_train)\n",
    "    proba = clf.score(X_test, y_test)\n",
    "    probas.append(proba)\n",
    "    print('.', end = '')\n",
    "\n",
    "print('\\nКачество модели: {:.2%}'.format(sum(probas) / len(probas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Окончательное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных из библиотеки диалогов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем все диалоги из архива\n",
    "with ZipFile('dialogues.zip') as file:  # read zip\n",
    "    with file.open('dialogues.txt') as txt:\n",
    "        dialogues_data = txt.read().decode('utf-8')\n",
    "\n",
    "dialogues = [dialogue.split('\\n')[:2] for dialogue in dialogues_data.split('\\n\\n')]\n",
    "dialogues = [dialogue for dialogue in dialogues if len(dialogue) == 2]\n",
    "\n",
    "dialogues_filtered = []\n",
    "alphabet = '1234567890- абвгдеёжзийклмнопрстуфхцчшщъыьэюяqwertyuiopasdfghjklzxcvbnm'\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    question = dialogue[0][2:].lower()\n",
    "    question = ''.join(char for char in question if char in alphabet)\n",
    "    question = question.strip()\n",
    "    answer = dialogue[1][2:].strip()\n",
    "    if question and answer:\n",
    "        dialogues_filtered.append((question, answer))\n",
    "\n",
    "dialogues_filtered = list(set(dialogues_filtered))\n",
    "\n",
    "search_structure = {}  # {word: [(q, a), (q, a), ...], ...}\n",
    "\n",
    "for question, answer in dialogues_filtered:\n",
    "    words = question.split(' ')\n",
    "    for word in words:\n",
    "        if word not in search_structure:\n",
    "            search_structure[word] = []\n",
    "        search_structure[word].append((question, answer))\n",
    "\n",
    "to_del = []\n",
    "for word in search_structure:\n",
    "    if len(search_structure[word]) > 10000:\n",
    "        to_del.append(word)\n",
    "\n",
    "for word in to_del:\n",
    "    search_structure.pop(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go_bot('расскажи пошлый анекдот')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
